{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_books(book_urls, Author_name,book_name):\n",
    "    # Create a list to store the DataFrames\n",
    "    dataframes = []\n",
    "    # Iterate over the book URLs and labels\n",
    "    for url, label, title in zip(book_urls, Author_name,book_name):\n",
    "        # Download book from Gutenberg\n",
    "        book = requests.get(url)\n",
    "        book = book.text\n",
    "        # Split book into a list of words\n",
    "        words = book.split()\n",
    "        # Create a list to store the partitions\n",
    "        partitions = []\n",
    "        # Use a for loop to sample 200 partitions of 100 words each\n",
    "        for i in range(200):\n",
    "            start_index = random.randint(0, len(words) - 100)\n",
    "            partition = words[start_index : start_index + 100]\n",
    "            partitions.append(\" \".join(partition))\n",
    "        # Create a Pandas DataFrame to store the partitions\n",
    "        data = {'text': partitions,'author': [label]*200,'book':title}\n",
    "        df = pd.DataFrame(data)\n",
    "        # Append the DataFrame to the list\n",
    "        dataframes.append(df)\n",
    "    # Concatenate the DataFrames into a single DataFrame\n",
    "    final_df = pd.concat(dataframes)\n",
    "    #return dataframe\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_urls = ['http://www.gutenberg.org/files/1342/1342-0.txt', 'http://www.gutenberg.org/files/84/84-0.txt','https://www.gutenberg.org/files/2701/2701-0.txt','https://www.gutenberg.org/files/1228/1228-0.txt','https://www.gutenberg.org/files/2600/2600-0.txt']\n",
    "Author_name = ['Jane Austen', 'Mary Wollstonecraft Shelley','Herman Melville', 'Charles Darwin','Leo Tolstoy']\n",
    "book_name = ['Pride and prejudice', 'Frankenstein','Moby-Dick','The Origin of Species','War and Peace']\n",
    "df = sample_books(book_urls, Author_name,book_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('text_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-a490076a9bbe>:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['text'] = df['text'].str.replace('[^a-zA-Z0-9\\s]','') # Remove punctuation\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the data\n",
    "df['text'] = df['text'].str.lower() # Convert to lowercase\n",
    "df['text'] = df['text'].str.replace('[^a-zA-Z0-9\\s]','') # Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['author']= le.fit_transform(df['author']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>book</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>as puzzle me exceedingly i can readily believe...</td>\n",
       "      <td>2</td>\n",
       "      <td>Pride and prejudice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>and i never spoke to you without rather wishin...</td>\n",
       "      <td>2</td>\n",
       "      <td>Pride and prejudice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i shall be uniformly silent and you may assure...</td>\n",
       "      <td>2</td>\n",
       "      <td>Pride and prejudice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>inclination any meeting with him would have be...</td>\n",
       "      <td>2</td>\n",
       "      <td>Pride and prejudice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>replied sir william from that knowledge of wha...</td>\n",
       "      <td>2</td>\n",
       "      <td>Pride and prejudice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>the quiet joyful and amused smile now habitual...</td>\n",
       "      <td>3</td>\n",
       "      <td>War and Peace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>think that i i understand quite understand i c...</td>\n",
       "      <td>3</td>\n",
       "      <td>War and Peace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>stood something seemed to be laughing a little...</td>\n",
       "      <td>3</td>\n",
       "      <td>War and Peace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>looked at him and without replying went on spe...</td>\n",
       "      <td>3</td>\n",
       "      <td>War and Peace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>his father to fits of bloodthirsty rage and wh...</td>\n",
       "      <td>3</td>\n",
       "      <td>War and Peace</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  author  \\\n",
       "0    as puzzle me exceedingly i can readily believe...       2   \n",
       "1    and i never spoke to you without rather wishin...       2   \n",
       "2    i shall be uniformly silent and you may assure...       2   \n",
       "3    inclination any meeting with him would have be...       2   \n",
       "4    replied sir william from that knowledge of wha...       2   \n",
       "..                                                 ...     ...   \n",
       "195  the quiet joyful and amused smile now habitual...       3   \n",
       "196  think that i i understand quite understand i c...       3   \n",
       "197  stood something seemed to be laughing a little...       3   \n",
       "198  looked at him and without replying went on spe...       3   \n",
       "199  his father to fits of bloodthirsty rage and wh...       3   \n",
       "\n",
       "                    book  \n",
       "0    Pride and prejudice  \n",
       "1    Pride and prejudice  \n",
       "2    Pride and prejudice  \n",
       "3    Pride and prejudice  \n",
       "4    Pride and prejudice  \n",
       "..                   ...  \n",
       "195        War and Peace  \n",
       "196        War and Peace  \n",
       "197        War and Peace  \n",
       "198        War and Peace  \n",
       "199        War and Peace  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training, validation, and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data into bag-of-words representation\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "train_matrix = vectorizer.fit_transform(train_df['text'])\n",
    "test_matrix = vectorizer.transform(test_df['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KMeans()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans()\n",
    "kmeans.fit(train_matrix,y=train_df['author'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[1. 0. 0. 0. 1. 0. 0. 1. 3. 2. 3. 2. 0. 3. 3. 3. 4. 3. 0. 4. 1. 2. 4. 1.\n 4. 4. 2. 3. 3. 3. 4. 2. 0. 1. 4. 2. 0. 1. 3. 2. 4. 2. 4. 3. 4. 4. 3. 0.\n 1. 3. 1. 3. 4. 1. 2. 2. 0. 2. 4. 3. 4. 2. 1. 4. 0. 0. 0. 3. 2. 1. 2. 1.\n 1. 0. 4. 4. 0. 2. 1. 4. 0. 2. 4. 2. 4. 1. 3. 0. 0. 4. 4. 1. 1. 4. 0. 1.\n 0. 2. 2. 3. 0. 4. 3. 4. 0. 0. 1. 3. 2. 3. 1. 3. 3. 3. 2. 1. 2. 3. 1. 4.\n 3. 1. 0. 4. 4. 1. 1. 1. 3. 3. 1. 3. 4. 3. 1. 2. 2. 4. 2. 2. 2. 4. 0. 4.\n 3. 3. 3. 4. 3. 4. 0. 2. 3. 1. 3. 1. 4. 0. 2. 3. 1. 0. 0. 0. 3. 0. 4. 0.\n 4. 4. 4. 1. 2. 3. 1. 4. 4. 4. 3. 0. 1. 0. 4. 1. 3. 2. 4. 4. 3. 0. 3. 3.\n 0. 2. 4. 1. 4. 4. 0. 2.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-947b563fb875>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'author'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\softwares\\Python\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, sample_weight)\u001b[0m\n\u001b[0;32m   1019\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1020\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_test_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1022\u001b[0m         \u001b[0mx_squared_norms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow_norms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m         \u001b[0msample_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\softwares\\Python\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py\u001b[0m in \u001b[0;36m_check_test_data\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    895\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    896\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_test_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 897\u001b[1;33m         X = self._validate_data(\n\u001b[0m\u001b[0;32m    898\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\softwares\\Python\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    575\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 577\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"X\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    578\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\softwares\\Python\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    877\u001b[0m             \u001b[1;31m# If input is 1D raise error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 879\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    880\u001b[0m                     \u001b[1;34m\"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    881\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[1. 0. 0. 0. 1. 0. 0. 1. 3. 2. 3. 2. 0. 3. 3. 3. 4. 3. 0. 4. 1. 2. 4. 1.\n 4. 4. 2. 3. 3. 3. 4. 2. 0. 1. 4. 2. 0. 1. 3. 2. 4. 2. 4. 3. 4. 4. 3. 0.\n 1. 3. 1. 3. 4. 1. 2. 2. 0. 2. 4. 3. 4. 2. 1. 4. 0. 0. 0. 3. 2. 1. 2. 1.\n 1. 0. 4. 4. 0. 2. 1. 4. 0. 2. 4. 2. 4. 1. 3. 0. 0. 4. 4. 1. 1. 4. 0. 1.\n 0. 2. 2. 3. 0. 4. 3. 4. 0. 0. 1. 3. 2. 3. 1. 3. 3. 3. 2. 1. 2. 3. 1. 4.\n 3. 1. 0. 4. 4. 1. 1. 1. 3. 3. 1. 3. 4. 3. 1. 2. 2. 4. 2. 2. 2. 4. 0. 4.\n 3. 3. 3. 4. 3. 4. 0. 2. 3. 1. 3. 1. 4. 0. 2. 3. 1. 0. 0. 0. 3. 0. 4. 0.\n 4. 4. 4. 1. 2. 3. 1. 4. 4. 4. 3. 0. 1. 0. 4. 1. 3. 2. 4. 4. 3. 0. 3. 3.\n 0. 2. 4. 1. 4. 4. 0. 2.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "y_pred = kmeans.predict(test_df['author'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "87d9b9d1e678527538d8142a74b02950316a4861c664997bcf14b93b840e5ec0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
